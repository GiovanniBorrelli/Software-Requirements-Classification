{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KOdqhFSgOREI1KdNp9ejk7KUMe2kNnQb","timestamp":1687740852508},{"file_id":"1XyBBC90-gB5Q0UHY4EzTVnzZbE-aR9sQ","timestamp":1687738796349},{"file_id":"1LAdahHCee7EA3TOppzmJIlTMwmT0CYJ3","timestamp":1687738672015},{"file_id":"12wDiaJvyoy9jdmMlpEK_Gn1MM6ijFfPM","timestamp":1687738497330}],"authorship_tag":"ABX9TyOsbb9ujyUNzb6QAZ67pwaj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# BERT-based Software Requirements Classification\n","\n","## Introduction\n","In this notebook, we will perform software requirements classification using the BERT model. The goal is to classify sentences into two categories: \"Requirements\" and \"Non-Requirements\". We will train multiple classifiers using cross-validation and evaluate their performance based on accuracy, precision, and recall.\n","\n","## Dataset Description\n","The dataset used in this analysis is stored in the file \"SoftwareReq300.xlsx\". It contains two attributes for each data point:\n","- \"Type\": A boolean attribute representing the type of the sentence (1 for \"Requirements\" and 0 for \"Non-Requirements\").\n","- \"Sentence\": A natural language sentence describing a software requirement.\n","\n"],"metadata":{"id":"viDJtWc1HiPC"}},{"cell_type":"markdown","source":["# Library Installation\n","Install the required libraries to use BERT model. In this case you need the `transformers` library."],"metadata":{"id":"iTyq5jxl_QMd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZ7YtFkKtMOb","executionInfo":{"status":"ok","timestamp":1687738650851,"user_tz":-120,"elapsed":11130,"user":{"displayName":"GIOVANNI BORRELLI","userId":"16609907105764854327"}},"outputId":"5b3615fb-4ce7-43a6-ed2f-4fad0397b148"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# Execution\n","Ensure that the dataset is present in the same directory of `BERTClassifier.py` and\n","run the script. Each classifier's performance is evaluated using accuracy, precision, and recall scores. Results are printed in a table format. On a side note, you can customize the code by using other classifiers or other metrics."],"metadata":{"id":"K1vjF6uP_gSX"}},{"cell_type":"code","source":["!python BERTClassifier.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHC2m7Tm-OdB","executionInfo":{"status":"ok","timestamp":1687737310949,"user_tz":-120,"elapsed":59468,"user":{"displayName":"GIOVANNI BORRELLI","userId":"16609907105764854327"}},"outputId":"4713c5d4-d7dc-4048-816b-9005a622a697"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","╒════════════════════╤════════════╤═════════════╤══════════╕\n","│ Model              │   Accuracy │   Precision │   Recall │\n","╞════════════════════╪════════════╪═════════════╪══════════╡\n","│ SVC                │   0.899666 │    0.878788 │ 0.892308 │\n","├────────────────────┼────────────┼─────────────┼──────────┤\n","│ MLPClassifier      │   0.889632 │    0.859259 │ 0.892308 │\n","├────────────────────┼────────────┼─────────────┼──────────┤\n","│ LogisticRegression │   0.886288 │    0.869231 │ 0.869231 │\n","╘════════════════════╧════════════╧═════════════╧══════════╛\n"]}]}]}